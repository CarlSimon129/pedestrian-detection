{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b1ef54",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea25032",
   "metadata": {},
   "source": [
    "Here, I'm following another PyTorch tutorial on finetuning torchvision models [https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html]\n",
    "\n",
    "The goal is to create a very simple baseline model, which is very fast to train. \n",
    "\n",
    "The idea is to download a pretrained backbone CNN and use it for feature extraction only. Then replace the classification head (to predict pedestrian or background only) and add regression head (to predict bounding boxes around pedestrians). Training should be very fast, since it's almost as training a linear regression (for regression head) and logistic regression (for classification head). \n",
    "\n",
    "To detect multiple pedestrians, we can slide a window and run the trained detector on each window. For example, if we use AlexNet as the backbone CNN, it uses 221x221 size images for input. A very simple approach is to just slide a window of this size over our input high resolution image, save the predicted bounding boxes on the way, and combine the predicted bounding boxes at the end. For combining, we can just take the intersection for bounding boxes that overlap. This way, the model even does some self correction since we run it multiple times. The testing has to run fast also so we should use some small and efficient backbone CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9470212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d250f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.8.1+cu102\n",
      "Torchvision Version:  0.9.1+cu102\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e65126c",
   "metadata": {},
   "source": [
    "We will use existing pretrained model (with modern CNN architecture) on 1000 class Imagenet dataset and use transfer learning. There are two types of transfer learning:\n",
    "\n",
    "* where we update all model's parameters for our new task, this is called *finetuning*;\n",
    "* where we only update the final layer weights from which we derive our new task predictions. It is called *feature extraction* because we use the pretrained CNN as a fixed feature-extractor, and only change the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605f5890",
   "metadata": {},
   "source": [
    "### Backbone CNN selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4fbbbf",
   "metadata": {},
   "source": [
    "Pretrained CNN models on ImageNet we can choose from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56a39278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet', 'inception']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cbbcaf",
   "metadata": {},
   "source": [
    "Let's choose AlexNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9993b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_names[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18176a9",
   "metadata": {},
   "source": [
    "You can download the dataset used in this tutorial here: https://download.pytorch.org/tutorial/hymenoptera_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f06b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/marko/data/baseline/hymenoptera_data\" # set the data dir\n",
    "num_classes = 2\n",
    "batch_size = 8 # change depending on how much memory you have\n",
    "num_epochs = 15\n",
    "feature_extract = True # we only update the reshaped layer params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc650947",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2226103f",
   "metadata": {},
   "source": [
    "### Model training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "287e3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, \n",
    "                num_epochs=25, is_inception=False):\n",
    "    ''' Copy pasted from tutorial. '''\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d339422a",
   "metadata": {},
   "source": [
    "When we are feature extracting only, we set all parameters of our model to have `.requires_grad = False` since we only want to compute gradients for the newly initialized layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27a0704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "147836a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    \"\"\" Trying with Alexnet only for now. We could try Resnet18\n",
    "    also, as our dataset is small and only has two classes. \n",
    "    See the code in tutorial on how to reshape other networks. \"\"\"\n",
    "\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "    \n",
    "    model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.classifier[6].in_features\n",
    "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "    input_size = 224\n",
    "    \n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f19c7d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26e9d2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d7e16",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "204bf226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f9c4768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_dir, x), \n",
    "                            data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {\n",
    "    x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                   batch_size=batch_size, \n",
    "                                   shuffle=True, \n",
    "                                   num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1aa9f3",
   "metadata": {},
   "source": [
    "### Create the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4f36d7",
   "metadata": {},
   "source": [
    "We gather the parameters to be optimized/updated in this run. \n",
    "Because we are doing feature extract method, we will only update the parameters that we have just initialized, i.e. the parameters with `requires_grad is True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "501557f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "## Send the model to the CPU or GPU device:\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe what parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58163d9d",
   "metadata": {},
   "source": [
    "### Run Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0728e55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.5088 Acc: 0.7705\n",
      "val Loss: 0.4402 Acc: 0.8627\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.3221 Acc: 0.9139\n",
      "val Loss: 0.4062 Acc: 0.8954\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.3133 Acc: 0.8893\n",
      "val Loss: 0.4167 Acc: 0.8889\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.2421 Acc: 0.9098\n",
      "val Loss: 0.3085 Acc: 0.9085\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.2920 Acc: 0.9057\n",
      "val Loss: 0.5238 Acc: 0.8562\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.2947 Acc: 0.9139\n",
      "val Loss: 0.3435 Acc: 0.8954\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.1954 Acc: 0.9467\n",
      "val Loss: 0.3855 Acc: 0.8693\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.1592 Acc: 0.9508\n",
      "val Loss: 0.3207 Acc: 0.9346\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.0924 Acc: 0.9631\n",
      "val Loss: 0.3486 Acc: 0.9150\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.2361 Acc: 0.9344\n",
      "val Loss: 0.3986 Acc: 0.9085\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.2030 Acc: 0.9426\n",
      "val Loss: 0.4078 Acc: 0.9281\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.1373 Acc: 0.9508\n",
      "val Loss: 0.4130 Acc: 0.9085\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.1253 Acc: 0.9426\n",
      "val Loss: 0.3780 Acc: 0.9085\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.1855 Acc: 0.9508\n",
      "val Loss: 0.4294 Acc: 0.9150\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.1779 Acc: 0.9385\n",
      "val Loss: 0.3653 Acc: 0.9020\n",
      "\n",
      "Training complete in 1m 32s\n",
      "Best val Acc: 0.934641\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(\n",
    "    model_ft, dataloaders_dict, criterion, \n",
    "    optimizer_ft, num_epochs=num_epochs, \n",
    "    is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c8c65b",
   "metadata": {},
   "source": [
    "***Training took about 1 minute and a half on 8th Gen Intel i5 cpu (i5-9500T CPU @ 2.20GHz).***\n",
    "\n",
    "And achieved a similar accuracy (0.934641) as in the tutorial (0.941176).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649397e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
